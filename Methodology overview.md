## NLP-for-Climate
This is a project developed for the course "Automated Text Processing for Social Sciences" taught by Ali Hürriyetoğlu

## Problem statement
As the increasing heat patterns in the world become hazard and disaster events, actions or policies are needed to protect lives, livelihoods, and assets. However, heat waves and ways to prevent their socio-economic-ecological-demographic effects are often neglected by the public and policymakers. Therefore, there is a need for more research and “documentation” (ENBEL, 2023), regarding the actions and harms to prevent further damage. So, the visibility of the impacts of heat waves and ways to mitigate as well as adapt must be enhanced to increase awareness among decision-makers, provide guidance, and propose policy solutions. 

## Research objective
This study will first establish a corpus from the “documents and publications” related to heat wave hazards.  Documents will be gathered from the Prevention Web (UNDRR) database. Then, the BERT Topic technique will be utilized on this corpus to identify the impacts of heat waves alongside actions for mitigation & adaptation observed in the corpus. The study will use the coherence score to evaluate the relevance of the topics. 

The main research questions that will guide this objective are:

•	How to establish a corpus using documents aiming to mitigate the impacts of heat waves?
•	How to identify the topics/characteristics from the documents?
•	How can these documents inform the development of comprehensive heat wave mitigation strategies for policymakers?

This is an initial step in the establishment of a specialized corpus. As an initial step, it will focus on identifying recurrent issues, making inferences based on them, and providing a path for the further development of this research to become an officially recognized corpus. Therefore, the main analysis methods are identifying the context(s) in which the tokens exist and the main topics via topic modeling. 

Identifying the context within a collection of documents involves analyzing the important words operationalized by TF-IDF scores and examining the frequent word co-occurrences based on n-grams. Identifying main topics involves examining the results of BERT topic and their coherence. 

# Define packages to use
This study utilizes nltk.tokenize library for tokenization
This study utilizes nltk.corpus library for removing stopwords
This study utilizes nltk.stem for lemmatization
This study utilizes gensim for building LDA model
This study utilizes pyLDAvis for evaluating the model

# Get texts from PDFs
The dataset involves various PDF documents. In order to prepare them for analysis, we need to extract the texts contained in these documents. 

# Preprocess and vectorize texts
